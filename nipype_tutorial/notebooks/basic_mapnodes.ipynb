{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../static/images/mapnode.png\"  width=\"300\">\n",
    "\n",
    "# MapNode\n",
    "\n",
    "If you want to iterate over a list of inputs, but need to feed all iterated outputs afterwards as one input (an array) to the next node, you need to use a **``MapNode``**. A ``MapNode`` is quite similar to a normal ``Node``, but it can take a list of inputs and operate over each input separately, ultimately returning a list of outputs. (The main homepage has a [nice section](http://nipype.readthedocs.io/en/latest/users/mapnode_and_iterables.html) about ``MapNode`` and ``iterables`` if you want to learn more).\n",
    "\n",
    "Let's demonstrate this with a simple function interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Function\n",
    "def square_func(x):\n",
    "    return x ** 2\n",
    "square = Function([\"x\"], [\"f_x\"], square_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this function just takes a numeric input and returns its squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
   "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square.run(x=2).outputs.f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to square a list of numbers? We could set an iterable and just split up the workflow in multiple sub-workflows. But say we were making a simple workflow that squared a list of numbers and then summed them. The sum node would expect a list, but using an iterable would make a bunch of sum nodes, and each would get one number from the list. The solution here is to use a `MapNode`.\n",
    "\n",
    "The `MapNode` constructor has a field called `iterfield`, which tells it what inputs should be expecting a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import MapNode\n",
    "square_node = MapNode(square, name=\"square\", iterfield=[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170904-05:47:03,281 workflow INFO:\n",
      "\t Executing node square in dir: /tmp/tmpuynl2xyq/square\n",
      "170904-05:47:03,294 workflow INFO:\n",
      "\t Executing node _square0 in dir: /tmp/tmpuynl2xyq/square/mapflow/_square0\n",
      "170904-05:47:03,309 workflow INFO:\n",
      "\t Executing node _square1 in dir: /tmp/tmpuynl2xyq/square/mapflow/_square1\n",
      "170904-05:47:03,317 workflow INFO:\n",
      "\t Executing node _square2 in dir: /tmp/tmpuynl2xyq/square/mapflow/_square2\n",
      "170904-05:47:03,324 workflow INFO:\n",
      "\t Executing node _square3 in dir: /tmp/tmpuynl2xyq/square/mapflow/_square3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9]"
      ]
     },
   "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_node.inputs.x = [0, 1, 2, 3]\n",
    "square_node.run().outputs.f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `iterfield` can take a list of names, you can operate over multiple sets of data, as long as they're the same length. The values in each list will be paired; it does not compute a combinatoric product of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_func(x, y):\n",
    "    return x ** y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170904-05:47:03,771 workflow INFO:\n",
      "\t Executing node power in dir: /tmp/tmp7_h6xuee/power\n",
      "170904-05:47:03,780 workflow INFO:\n",
      "\t Executing node _power0 in dir: /tmp/tmp7_h6xuee/power/mapflow/_power0\n",
      "170904-05:47:03,790 workflow INFO:\n",
      "\t Executing node _power1 in dir: /tmp/tmp7_h6xuee/power/mapflow/_power1\n",
      "170904-05:47:03,799 workflow INFO:\n",
      "\t Executing node _power2 in dir: /tmp/tmp7_h6xuee/power/mapflow/_power2\n",
      "170904-05:47:03,806 workflow INFO:\n",
      "\t Executing node _power3 in dir: /tmp/tmp7_h6xuee/power/mapflow/_power3\n",
      "[1, 1, 4, 27]\n"
     ]
    }
   ],
   "source": [
    "power = Function([\"x\", \"y\"], [\"f_xy\"], power_func)\n",
    "power_node = MapNode(power, name=\"power\", iterfield=[\"x\", \"y\"])\n",
    "power_node.inputs.x = [0, 1, 2, 3]\n",
    "power_node.inputs.y = [0, 1, 2, 3]\n",
    "print(power_node.run().outputs.f_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But not every input needs to be an iterfield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170904-05:47:04,103 workflow INFO:\n",
      "\t Executing node power in dir: /tmp/tmplaunq_yj/power\n",
      "170904-05:47:04,113 workflow INFO:\n",
      "\t Executing node _power0 in dir: /tmp/tmplaunq_yj/power/mapflow/_power0\n",
      "170904-05:47:04,122 workflow INFO:\n",
      "\t Executing node _power1 in dir: /tmp/tmplaunq_yj/power/mapflow/_power1\n",
      "170904-05:47:04,132 workflow INFO:\n",
      "\t Executing node _power2 in dir: /tmp/tmplaunq_yj/power/mapflow/_power2\n",
      "170904-05:47:04,139 workflow INFO:\n",
      "\t Executing node _power3 in dir: /tmp/tmplaunq_yj/power/mapflow/_power3\n",
      "[0, 1, 8, 27]\n"
     ]
    }
   ],
   "source": [
    "power_node = MapNode(power, name=\"power\", iterfield=[\"x\"])\n",
    "power_node.inputs.x = [0, 1, 2, 3]\n",
    "power_node.inputs.y = 3\n",
    "print(power_node.run().outputs.f_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of `iterables`, each underlying `MapNode` execution can happen in **parallel**. Hopefully, you see how these tools allow you to write flexible, reusable workflows that will help you processes large amounts of data efficiently and reproducibly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is this important?\n",
    "\n",
    "Let's consider we have multiple functional images (A) and each of them should be motioned corrected (B1, B2, B3,..). But afterwards, we want to put them all together into a GLM, i.e. the input for the GLM should be an array of [B1, B2, B3, ...]. [Iterables](basic_iteration.ipynb) can't do that. They would split up the pipeline. Therefore, we need **MapNodes**.\n",
    "\n",
    "<img src=\"../static/images/mapnode.png\"  width=\"300\">\n",
    "\n",
    "Let's look at a simple example, where we want to motion correct two functional images. For this we need two nodes:\n",
    " - Gunzip, to unzip the files (plural)\n",
    " - Realign, to do the motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.algorithms.misc import Gunzip\n",
    "from nipype.interfaces.spm import Realign\n",
    "from nipype.pipeline.engine import Node, MapNode, Workflow\n",
    "\n",
    "files = ['/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz',\n",
    "         '/data/ds000114/sub-02/ses-test/func/sub-02_ses-test_task-fingerfootlips_bold.nii.gz']\n",
    "\n",
    "realign = Node(Realign(register_to_mean=True),\n",
    "               name='motion_correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to specify the input for the **Gunzip** node with a simple **Node**, we get the following error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TraitError",
     "evalue": "The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz', '/data/ds000114/sub-02/ses-test/func/sub-02_ses-test_task-fingerfootlips_bold.nii.gz'] <class 'list'> was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraitError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4c705ede4d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgunzip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGunzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gunzip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgunzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/neuro3/lib/python3.6/site-packages/nipype/interfaces/traits_extension.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mNote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0;34m'fast validator'\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mperforms\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mvalidated_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalidated_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neuro3/lib/python3.6/site-packages/traits/trait_types.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_editor\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neuro3/lib/python3.6/site-packages/traits/trait_handlers.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m    171\u001b[0m         raise TraitError( object, name, self.full_info( object, name, value ),\n\u001b[0;32m--> 172\u001b[0;31m                           value )\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull_info\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTraitError\u001b[0m: The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz', '/data/ds000114/sub-02/ses-test/func/sub-02_ses-test_task-fingerfootlips_bold.nii.gz'] <class 'list'> was specified."
     ]
    }
   ],
   "source": [
    "gunzip = Node(Gunzip(), name='gunzip',)\n",
    "gunzip.inputs.in_file = files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "TraitError: The 'in_file' trait of a GunzipInputSpec instance must be an existing file name, but a value of ['/data/ds102/sub-01/func/sub-01_task-flanker_run-1_bold.nii.gz', '/data/ds102/sub-01/func/sub-01_task-flanker_run-2_bold.nii.gz'] <type 'list'> was specified.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we do it with a **MapNode**, it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip = MapNode(Gunzip(), name='gunzip',\n",
    "                 iterfield=['in_file'])\n",
    "gunzip.inputs.in_file = files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just have to create a workflow, connect the nodes and we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170904-05:47:23,396 workflow INFO:\n",
      "\t Workflow realign_with_spm settings: ['check', 'execution', 'logging']\n",
      "170904-05:47:23,401 workflow INFO:\n",
      "\t Running in parallel.\n",
      "170904-05:47:23,405 workflow INFO:\n",
      "\t Executing: gunzip ID: 0\n",
      "170904-05:47:23,408 workflow INFO:\n",
      "\t Adding 2 jobs for mapnode gunzip\n",
      "170904-05:47:23,414 workflow INFO:\n",
      "\t Executing: _gunzip0 ID: 2\n",
      "170904-05:47:23,416 workflow INFO:\n",
      "\t Executing: _gunzip1 ID: 3\n",
      "170904-05:47:23,417 workflow INFO:\n",
      "\t Executing node _gunzip0 in dir: /output/realign_with_spm/gunzip/mapflow/_gunzip0170904-05:47:23,419 workflow INFO:\n",
      "\t Executing node _gunzip1 in dir: /output/realign_with_spm/gunzip/mapflow/_gunzip1\n",
      "\n",
      "170904-05:47:24,103 workflow INFO:\n",
      "\t [Job finished] jobname: _gunzip0 jobid: 2\n",
      "170904-05:47:24,113 workflow INFO:\n",
      "\t [Job finished] jobname: _gunzip1 jobid: 3\n",
      "170904-05:47:24,115 workflow INFO:\n",
      "\t Executing: gunzip ID: 0\n",
      "170904-05:47:24,119 workflow INFO:\n",
      "\t Executing node gunzip in dir: /output/realign_with_spm/gunzip\n",
      "170904-05:47:24,126 workflow INFO:\n",
      "\t Executing node _gunzip0 in dir: /output/realign_with_spm/gunzip/mapflow/_gunzip0\n",
      "170904-05:47:24,129 workflow INFO:\n",
      "\t Collecting precomputed outputs\n",
      "170904-05:47:24,136 workflow INFO:\n",
      "\t Executing node _gunzip1 in dir: /output/realign_with_spm/gunzip/mapflow/_gunzip1\n",
      "170904-05:47:24,139 workflow INFO:\n",
      "\t Collecting precomputed outputs\n",
      "170904-05:47:24,144 workflow INFO:\n",
      "\t [Job finished] jobname: gunzip jobid: 0\n",
      "170904-05:47:24,147 workflow INFO:\n",
      "\t Executing: motion_correction ID: 1\n",
      "170904-05:47:24,153 workflow INFO:\n",
      "\t Executing node motion_correction in dir: /output/realign_with_spm/motion_correction\n",
      "170904-05:49:01,535 workflow INFO:\n",
      "\t [Job finished] jobname: motion_correction jobid: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f11c340fbe0>"
      ]
     },
   "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcflow = Workflow(name='realign_with_spm')\n",
    "mcflow.connect(gunzip, 'out_file', realign, 'in_files')\n",
    "mcflow.base_dir = '/output'\n",
    "mcflow.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
